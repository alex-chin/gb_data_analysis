{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Задание № 6\n",
    "\n",
    "### Урок 6. Градиентный бустинг (AdaBoost)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задание\n",
    "\n",
    "1. Для реализованной в методичке модели градиентного бустинга построить графики зависимости ошибки от количества деревьев в ансамбле и от максимальной глубины деревьев. Сделать выводы о зависимости ошибки от этих параметров.\n",
    "2. **(*)** Модифицировать реализованный алгоритм, чтобы получился стохастический градиентный бустинг. Размер подвыборки принять равным 0.5. Сравнить на одном графике кривые изменения ошибки на тестовой выборке в зависимости от числа итераций.\n",
    "3. **(*)** Реализовать алгоритм градиетного бустинга, основанный на реализации решающего дерева из ДЗ4 / методички к уроку 4. Сделать выводы о качестве алгоритма по сравнению с реализацией из п.1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Напишем функцию, реализующую предсказание в градиентном бустинге."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import model_selection\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class GBGradBoost:\n",
    "    n_trees = 0\n",
    "    max_depth = 0\n",
    "    eta = 0\n",
    "    tree_list = []\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    coefs =[]\n",
    "\n",
    "\n",
    "    def params(self, n_trees=10, max_depth=3, eta=1):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.eta = eta\n",
    "        self.coefs = [1] * n_trees\n",
    "\n",
    "    # def __init__(self, X, y, test_size=0.25):\n",
    "    def __init__(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "            model_selection.train_test_split(X, y, test_size=test_size)\n",
    "        self.params()\n",
    "\n",
    "    def gb_predict(self, X, coef_list, eta):\n",
    "        # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "        # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании прибавляются с шагом eta\n",
    "        return np.array([sum([eta* coef * alg.predict([x])[0] for alg, coef in zip(self.tree_list, coef_list)]) for x in X])\n",
    "\n",
    "\n",
    "    # В качестве функционала ошибки будем использовать среднеквадратичную ошибку. Реализуем соответствующую функцию.\n",
    "    def mean_squared_error(self, y_real, prediction):\n",
    "        return (sum((y_real - prediction) ** 2)) / len(y_real)\n",
    "\n",
    "    def func_loss(self, y_real, prediction):\n",
    "        pass\n",
    "\n",
    "    def bias(self, y, z):\n",
    "        return (y - z)\n",
    "\n",
    "    def grad(self, y, z):\n",
    "        pass\n",
    "\n",
    "    # Реализуем функцию обучения градиентного бустинга.\n",
    "    # def gb_fit(self, n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    def gb_fit(self):\n",
    "        # Деревья будем записывать в список\n",
    "        # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "        self.tree_list = []\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42)\n",
    "            # инициализируем бустинг начальным алгоритмом, возвращающим ноль,\n",
    "            # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "            if len(self.tree_list) == 0:\n",
    "                # обучаем первое дерево на обучающей выборке\n",
    "                tree.fit(self.X_train, self.y_train)\n",
    "\n",
    "                train_errors.append(self.mean_squared_error(self.y_train, self.gb_predict(self.X_train, self.coefs)))\n",
    "                test_errors.append(self.mean_squared_error(self.y_test, self.gb_predict(self.X_test, self.coefs)))\n",
    "            else:\n",
    "                # Получим ответы на текущей композиции\n",
    "                target = self.gb_predict(self.X_train, self.coefs, self.eta)\n",
    "\n",
    "                # алгоритмы начиная со второго обучаем на сдвиг\n",
    "                tree.fit(self.X_train, self.bias(self.y_train, target))\n",
    "\n",
    "                train_errors.append(self.mean_squared_error(self.y_train, self.gb_predict(self.X_train, self.tree_list, self.coefs, self.eta)))\n",
    "                test_errors.append(self.mean_squared_error(self.y_test, self.gb_predict(self.X_test, self.tree_list, self.coefs, self.eta)))\n",
    "\n",
    "            trees.append(tree)\n",
    "\n",
    "        return trees, train_errors, test_errors\n",
    "\n",
    "    def evaluate_alg(self, X_train, X_test, y_train, y_test, trees, coefs, eta):\n",
    "        train_prediction = self.gb_predict(X_train, trees, coefs, eta)\n",
    "\n",
    "        print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "        с шагом {eta} на тренировочной выборке: {self.mean_squared_error(y_train, train_prediction)}')\n",
    "\n",
    "        test_prediction = self.gb_predict(X_test, trees, coefs, eta)\n",
    "\n",
    "        print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "        с шагом {eta} на тестовой выборке: {self.mean_squared_error(y_test, test_prediction)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь обучим несколько моделей с разными параметрами и исследуем их поведение."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 10\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 3\n",
    "# Шаг\n",
    "eta = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\8523~1\\AppData\\Local\\Temp/ipykernel_33176/1198224744.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mgb_gboost\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGBGradBoost\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtrees\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_errors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_errors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgb_gboost\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgb_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_depth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoefs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mgb_gboost\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate_alg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrees\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoefs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "gb_gboost = GBGradBoost()\n",
    "\n",
    "trees, train_errors, test_errors = gb_gboost.gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)\n",
    "gb_gboost.evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(max_depth=3, random_state=42)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}